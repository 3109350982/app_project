# services/xhs_collector.py
import asyncio
import time
from typing import List

from browser_manager import BrowserManager
from data_storage import DataStorage
from settings import SETTINGS


class XHSCollectorService:
    def __init__(self, browser_manager: BrowserManager, storage: DataStorage):
        self.browser_manager = browser_manager
        self.storage = storage
        self._running = False

    async def run(
        self,
        keywords,                      # å…¼å®¹ string æˆ– list[str]
        items_per_keyword: int = 30,   # ä¸ app.py è·¯ç”±ä¿æŒä¸€è‡´
        item_type: str = "video_or_note",
    ):
        """
        åªåœ¨æœç´¢ç»“æœé¡µé‡‡é›†ï¼›æ¯ä¸ªå…³é”®è¯é™åˆ¶æ•°é‡ï¼›é€ä¸ªè°ƒç”¨ç°æœ‰çš„ _collect_for_keywordã€‚
        """
        self._running = True

        # å…è®¸ keywords ä¼ å…¥å­—ç¬¦ä¸²ï¼ˆç©ºæ ¼/é€—å·åˆ†éš”ï¼‰æˆ– list[str]
        if isinstance(keywords, str):
            kws = [k for k in keywords.replace("ï¼Œ", " ").replace(",", " ").split() if k]
        else:
            kws = [k for k in (keywords or []) if isinstance(k, str) and k.strip()]

        print(f"ğŸ” [XHS][Collector] æ”¶åˆ°ä»»åŠ¡ï¼š{kws}ï¼Œitems_per_keyword={items_per_keyword}, item_type={item_type}")

        for kw in kws:
            if not self._running:
                break
            await self._collect_for_keyword(kw, items_per_keyword, item_type)

        self._running = False



    async def stop(self):
        self._running = False

    async def _collect_for_keyword(
        self, kw: str, items_per_keyword: int, item_type: str
    ):
        page = await self.browser_manager.new_page()
        print(f"ğŸ” [XHS][Collector] å‡†å¤‡é‡‡é›†å…³é”®è¯: {kw}ï¼ŒæœŸæœ›æ•°é‡: {items_per_keyword}")
        url = SETTINGS["XHS"]["SEARCH_URL_TEMPLATE"].format(kw=kw)
        selectors = SETTINGS["XHS"]["SELECTORS"]

        try:
            print(f"ğŸŒ [XHS][Collector] è·³è½¬æœç´¢é¡µ: {url}")
            await page.goto(url, timeout=60000)
            print("ğŸŒ [XHS][Collector] æœç´¢é¡µåŠ è½½å®Œæˆï¼Œå¼€å§‹è§£æå¡ç‰‡...")
            await asyncio.sleep(2)

            collected = 0
            max_scroll = 40
            scroll_count = 0

            while collected < items_per_keyword and scroll_count < max_scroll:
                cards = await page.query_selector_all(
                    selectors["search_result_item"]
                )
                card_count = len(cards)
                print(
                    f"ğŸ” [XHS][Collector] æœ¬æ¬¡æ»šåŠ¨åæ£€æµ‹åˆ°å¡ç‰‡æ•°é‡: {card_count}ï¼Œå·²é‡‡é›†: {collected}ï¼Œscroll={scroll_count}"
                )
                for card in cards:
                    if collected >= items_per_keyword:
                        break
                    # é¢„è®¾å˜é‡ï¼Œé¿å…è§£æè¿‡ç¨‹ä¸­å¼‚å¸¸å¯¼è‡´æœªèµ‹å€¼çš„å±€éƒ¨å˜é‡è¢«å¼•ç”¨
                    href = ""
                    title = ""
                    author_name = ""
                    try:
                        link_el = await card.query_selector(selectors["item_link"])
                        if not link_el:
                            continue
                        href = await link_el.get_attribute("href")
                        if not href:
                            continue
                        if href.startswith("/"):
                            href = "https://www.xiaohongshu.com" + href

                        async def _first_text(el, sel_list):
                            # å…¼å®¹å­—ç¬¦ä¸²æˆ–åˆ—è¡¨ä¼ å…¥
                            if isinstance(sel_list, str):
                                selectors_list = [sel_list]
                            else:
                                selectors_list = sel_list or []

                            async def _extract_from_element(elem):
                                if not elem:
                                    return ""
                                # å°è¯•è¯»å–å¯è§æ–‡æœ¬
                                text = (await elem.inner_text() or "").strip()
                                if not text:
                                    text = (await elem.text_content() or "").strip()
                                if text:
                                    return text

                                # å¸¸è§å±æ€§å…œåº•
                                for attr in [
                                    "title",
                                    "aria-label",
                                    "alt",
                                    "data-title",
                                    "data-desc",
                                    "data-name",
                                    "data-nickname",
                                ]:
                                    attr_text = await elem.get_attribute(attr)
                                    if attr_text and attr_text.strip():
                                        return attr_text.strip()
                                return ""

                            for sel in selectors_list:
                                if not sel:
                                    continue
                                targets = await el.query_selector_all(sel)
                                for target in targets:
                                    text = await _extract_from_element(target)
                                    if text:
                                        return text
                            return ""

                        title_selectors = (
                            selectors.get("item_title_selectors")
                            or [selectors.get("item_title")]
                        )
                        try:
                            title = await _first_text(card, title_selectors)
                        except Exception as e:
                            # æ ‡é¢˜è§£æå¼‚å¸¸ç›´æ¥å…œåº•ä¸ºç©ºï¼Œé¿å…ä¸­æ–­
                            print(f"[XHSCollector] title parse error: {e}")
                            title = ""

                        # æœ‰äº›å¡ç‰‡æŠŠæ ‡é¢˜æ”¾åœ¨é“¾æ¥çš„ title/aria-label ä¸Šï¼Œåšè¡¥å……å…œåº•
                        if (not title) and link_el:
                            link_title = (
                                (await link_el.get_attribute("title"))
                                or (await link_el.get_attribute("aria-label"))
                                or (await link_el.get_attribute("alt"))
                                or ""
                            ).strip()
                            if link_title:
                                title = link_title

                        # å¦‚æœæ ‡é¢˜ä»ä¸ºç©ºï¼Œå°è¯•ä»æ•´å¼ å¡ç‰‡çš„æ–‡æœ¬ä¸­ç²—ç•¥æå–
                        if not title:
                            try:
                                raw_card_text = await card.inner_text()
                            except Exception:
                                raw_card_text = ""

                            lines = [
                                l.strip()
                                for l in (raw_card_text or "").replace("\r", "").split("\n")
                                if l.strip()
                            ]

                            # è¿‡æ»¤æ˜æ˜¾ä¸æ˜¯æ ‡é¢˜çš„è¡Œï¼ˆç‚¹èµã€è¯„è®ºã€ä½œè€…ç­‰ï¼‰
                            noise_keywords = [
                                "èµ",
                                "è¯„è®º",
                                "æ”¶è—",
                                "è½¬å‘",
                                "å‘å¸ƒ",
                                "å°æ—¶å‰",
                                "åˆšåˆš",
                                "æ˜¨å¤©",
                                "å‰",
                                "å",
                            ]
                            candidate_lines = []
                            for line in lines:
                                # æ’é™¤å·²ç»è§£æåˆ°çš„ä½œè€…ã€æ—¶é—´ã€ç‚¹èµç­‰å†…å®¹
                                if (author_name and line == author_name) or (
                                    publish_time and line == publish_time
                                ):
                                    continue
                                if like_text and line == like_text:
                                    continue
                                if any(kw in line for kw in noise_keywords):
                                    continue
                                candidate_lines.append(line)

                            # ä¼˜å…ˆé€‰æ‹©æœ€é•¿çš„å€™é€‰è¡Œï¼Œå°½é‡æ¥è¿‘æœŸæœ›çš„æ ‡é¢˜
                            if candidate_lines:
                                title = max(candidate_lines, key=len)

                        try:
                            author_name = await _first_text(
                                card, selectors.get("item_author_selectors", [])
                            )
                        except Exception as e:
                            print(f"[XHSCollector] author parse error: {e}")
                            author_name = ""
                        if not author_name:
                            # å…¼å®¹éƒ¨åˆ†å¡ç‰‡ä½œè€…æ˜µç§°åœ¨ data-* å±æ€§é‡Œ
                            data_attrs = [
                                "data-author-name",
                                "data-nickname",
                                "data-user-name",
                                "data-user",
                            ]
                            data_author = ""
                            if link_el:
                                for attr in data_attrs:
                                    val = await link_el.get_attribute(attr)
                                    if val and val.strip():
                                        data_author = val.strip()
                                        break
                            if not data_author:
                                # æœ‰äº›æ˜µç§°æŒ‚åœ¨æœ€å¤–å±‚å¡ç‰‡èŠ‚ç‚¹ä¸Š
                                for attr in data_attrs:
                                    val = await card.get_attribute(attr)
                                    if val and val.strip():
                                        data_author = val.strip()
                                        break

                            if data_author:
                                author_name = data_author
                            else:
                                author_name = await _first_text(
                                    card, selectors.get("item_author_fallback_selectors", [])
                                )
                        # åŸ _parse_int æ›¿æ¢ä¸ºï¼š
                        def _parse_int(text: str) -> int:
                            t = (text or "").strip().lower()
                            # ç»Ÿä¸€å»æ‰ç©ºæ ¼å’Œç¬¦å·
                            t = t.replace("+", "").replace(",", "")
                            # ç‰¹æ®Šå•ä½ï¼šä¸‡ / w / k
                            if "ä¸‡" in t or "w" in t:
                                # ä¾‹: "1.2ä¸‡" / "2w" / "2.3w+"
                                num = "".join(c for c in t if (c.isdigit() or c == ".")) or "0"
                                return int(float(num) * 10000)
                            if "k" in t:
                                # ä¾‹: "3k" => 3000
                                num = "".join(c for c in t if (c.isdigit() or c == ".")) or "0"
                                return int(float(num) * 1000)
                            # çº¯æ•°å­—
                            digits = "".join(c for c in t if c.isdigit())
                            return int(digits) if digits else 0


                        like_count = 0
                        comment_count = 0

                        try:
                            like_text = await _first_text(
                                card, selectors.get("item_like_count_selectors", [])
                            )
                        except Exception as e:
                            print(f"[XHSCollector] like parse error: {e}")
                            like_text = ""
                        if like_text:
                            like_count = _parse_int(like_text)

                        try:
                            comment_text = await _first_text(
                                card, selectors.get("item_comment_count_selectors", [])
                            )
                        except Exception as e:
                            print(f"[XHSCollector] comment parse error: {e}")
                            comment_text = ""
                        if comment_text:
                            comment_count = _parse_int(comment_text)

                        try:
                            publish_time = await _first_text(
                                card, selectors.get("item_publish_time_selectors", [])
                            )
                        except Exception as e:
                            print(f"[XHSCollector] publish time parse error: {e}")
                            publish_time = ""
                        publish_ts = int(time.time())

                        # ç¡®ä¿å…³é”®å­—æ®µä¸ºå­—ç¬¦ä¸²ï¼Œé¿å…ç©ºå€¼å¯¼è‡´çš„å¼‚å¸¸
                        title = title or ""
                        author_name = author_name or ""

                        item = {
                            "source": "xhs",
                            "item_url": href,
                            "title": title,
                            "author_name": author_name,
                            "keyword": kw,
                            "publish_time": publish_time,
                            "publish_ts": publish_ts,
                            "like_count": like_count,
                            "collect_count": 0,
                            "comment_count": comment_count,
                            "type": item_type,
                        }
                        self.storage.insert_or_update_item(item)
                        collected += 1
                        print(
                            f"âœ… [XHS][Collector] é‡‡é›†æˆåŠŸï¼škw={kw} url={href} title={title} like={like_count}"
                        )
                    except Exception as e:
                        try:
                            snapshot = (await card.inner_html()) if card else ""
                        except Exception:
                            snapshot = ""
                        print(
                            "[XHSCollector] card parse error",
                            e,
                            "| partial data => href:",
                            href,
                            "title:",
                            title,
                            "author:",
                            author_name,
                        )
                        if snapshot:
                            print("[XHSCollector] card html snippet:", snapshot[:500])

                if collected >= items_per_keyword:
                    break

                await page.evaluate(
                    "window.scrollBy(0, window.innerHeight || 800);"
                )
                await asyncio.sleep(1)
                scroll_count += 1
            print(
                f"âœ… [XHS][Collector] å…³é”®è¯ {kw} é‡‡é›†ç»“æŸï¼Œæœ€ç»ˆæ•°é‡={collected}ï¼Œæ€»æ»šåŠ¨æ¬¡æ•°={scroll_count}"
            )
        finally:
            try:
                await page.close()
            except Exception:
                pass
